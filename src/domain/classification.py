import os.path
import pickle
import re
from typing import Any, Dict, List, Optional, Union

import numpy as np
import pandas as pd
from imblearn.combine import SMOTETomek
from loguru import logger
from osgeo import gdal
from osgeo.gdal import Dataset, Driver
from pandas import DataFrame
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

from additional.logger_configuration import configurate_logger
from domain.shared import Shared
from exceptions.exceptions import MonthExtractionException, LibraryException
from schema.accuracy_metrics import AccuracyMetrics
from schema.algorithm import Algorithm
from schema.classification_type import ClassificationType
from schema.columns import DataColumns, LabelColumn
from schema.constants import Constants
from schema.file_modes import FileMode
from schema.file_types import FileType
from schema.folder_types import FolderType
from schema.formats import Format
from schema.library_type import LibraryType
from schema.metadata_types import ParametersJson
from schema.months import Month
from schema.reading_types import ReadingType
from schema.regexes import Regex
from schema.root_folders import RootFolders
from schema.unit_type import UnitType
from schema.yes_no import YesNo

configurate_logger()


class Classification:
    MAX_DEPTH: int = 20
    ESTIMATORS: int = 100
    N_JOBS: int = -1
    NO_DATA_VALUE: int = 0

    def __init__(self, shared: Shared):
        self.shared: Shared = shared
        self.files: List[str] = self.shared.choose_files_from_folder(algorithm=Algorithm.CLASSIFICATION)
        self.model: ClassificationType = self._choose_classification_type()
        self.parameters: Dict[str, Any] = self.shared.get_parameters(files_paths=self.files)
        self.folders: Dict[FolderType, str] = self.parameters[ParametersJson.FOLDERS]
        self.models: Dict[Month | ClassificationType, str] = {}

    def classify(self) -> None:
        if self._ask_for_relearning():
            self._train_and_save_model()

        self.models = self._get_model_paths()
        self.shared.create_folder(path=self.folders[FolderType.CLASSIFIED])
        self.shared.create_folder(path=self.folders[FolderType.CONFIDENCE])

        pbar: tqdm = tqdm(self.files, unit=UnitType.FILE)
        for index, file in enumerate(pbar):
            file_name: str = os.path.basename(str(file))

            if self.model == ClassificationType.GROUND:
                file_month: int = self._get_month(file_name=file_name)

                month_map: Dict[int, Month] = self._month_map()
                month_enum: Month = month_map[file_month]
                pbar.set_description(f"Classifying {index + 1} image with {month_enum.value.capitalize()} model")
                model = self._load_model(month=month_enum)
            else:
                model = self._load_model(month=self.model)
                pbar.set_description(f"Classifying {index + 1} image with {self.model.value.capitalize()} model")

            output_path: str = os.path.join(self.folders[FolderType.CLASSIFIED], file_name)

            confidence_file_name: str = f"Confidence {file_name}"
            conf_output_path: str = os.path.join(self.folders[FolderType.CONFIDENCE], confidence_file_name)

            ds: Any = gdal.Open(file, gdal.GA_ReadOnly)
            rows: int = ds.RasterYSize
            cols: int = ds.RasterXSize
            bands: int = ds.RasterCount
            geo_trans: Any = ds.GetGeoTransform()
            proj: Any = ds.GetProjectionRef()
            array: np.array = ds.ReadAsArray().astype(ReadingType.INT16)
            ds: None = None

            array: np.array = np.stack(array, axis=2)
            array: np.array = np.reshape(array, [rows * cols, bands])

            class_result: np.array = model.predict(array)
            probabilities: np.array = model.predict_proba(array)
            confidence: np.array = np.max(probabilities, axis=1)

            class_result: np.array = class_result.reshape((rows, cols))
            confidence: np.array = confidence.reshape((rows, cols))

            class_result: np.array = self._remove_clouds(input_file=str(file), class_result=class_result)
            confidence: np.array = self._remove_clouds(input_file=str(file), class_result=confidence)
            confidence: np.array = np.round(confidence, decimals=2)

            self._createGeotiff(outRaster=output_path, dataG=class_result, transform=geo_trans, proj=proj)
            self._createGeotiff(
                outRaster=conf_output_path, dataG=confidence, transform=geo_trans, proj=proj, data_type=gdal.GDT_Float32
            )
        logger.warning("End of classification process.")
        return None

    @staticmethod
    def _remove_clouds(input_file: str, class_result: np.array) -> np.array:
        test_raster: Any = gdal.Open(input_file, gdal.GA_ReadOnly)
        band_1: Any = test_raster.GetRasterBand(1)
        band_1_array: np.array = band_1.ReadAsArray().astype(ReadingType.INT16)
        class_result[band_1_array == 0] = 0
        return class_result

    def _createGeotiff(
        self, outRaster: str, dataG: np.array, transform: Any, proj: Any, data_type: int = gdal.GDT_Byte
    ):
        driver: Driver = gdal.GetDriverByName(Format.GTIFF)
        rowsG, colsG = dataG.shape
        rasterDS: Optional[Dataset] = driver.Create(outRaster, colsG, rowsG, 1, data_type)
        rasterDS.SetGeoTransform(transform)
        rasterDS.SetProjection(proj)
        band: Any = rasterDS.GetRasterBand(1)
        band.SetNoDataValue(self.NO_DATA_VALUE)
        band.WriteArray(dataG)
        rasterDS = None

    def _get_model_paths(self) -> Dict[Month, str]:
        model_paths: Dict[Month | ClassificationType, str] = {}
        model_folder = self.shared.root_folders[RootFolders.MODEL_FOLDER]

        model_names = os.listdir(model_folder)

        for model_name in model_names:
            model_path: str = os.path.join(model_folder, model_name)
            for month in Month:
                if month.value in model_name.lower():
                    model_paths[month] = model_path
                    break
            if ClassificationType.URBAN.value.lower() in model_name.lower():
                model_paths[ClassificationType.URBAN] = model_path
            if ClassificationType.FOREST.value.lower() in model_name.lower():
                model_paths[ClassificationType.FOREST] = model_path
        return model_paths

    def _ask_for_relearning(self) -> bool:
        while True:
            boolean: str = str(input("Do you want to relearn classification models (Y/N)? "))
            if boolean.lower() == YesNo.YES:
                return True
            elif boolean.lower() == YesNo.NO:
                return False
            self.shared.clear_console()

    def _group_libraries(self, all_libraries: List[str]) -> Dict[Union[Month, str], Dict[LibraryType, str]]:
        if self.model == ClassificationType.GROUND:
            group_libraries: Dict[Month | ClassificationType, Dict[LibraryType, str]] = {month: {} for month in Month}
            for library in all_libraries:
                library_name: str = os.path.basename(library)
                for month in Month:
                    if str(month) in library_name.lower():
                        for library_type in LibraryType:
                            if str(library_type) in library_name.lower():
                                group_libraries[month][library_type] = library
        elif self.model in (ClassificationType.FOREST, ClassificationType.URBAN):
            model_name = self.model.value.lower()
            group_libraries: Dict[Month | ClassificationType, Dict[LibraryType, str]] = {self.model: {}}
            for library in all_libraries:
                library_name: str = os.path.basename(library)
                if model_name in library_name.lower():
                    for library_type in LibraryType:
                        if str(library_type) in library_name.lower():
                            group_libraries[self.model][library_type] = library
        else:
            raise LibraryException(
                f"Cannot find group of training and validation" f" training sets for {self.model.value} model"
            )
        return {key: value for key, value in group_libraries.items() if value and len(value) == 2}

    def _train_and_save_model(self) -> None:
        self._initialize_file()
        all_libraries: List[str] = self.shared.list_dir(dir_=self.shared.root_folders[RootFolders.LEARNING_FOLDER])

        grouped_libraries: Dict[Month, Dict[LibraryType, str]] = self._group_libraries(all_libraries=all_libraries)
        print()
        for month, libraries_info in grouped_libraries.items():
            logger.info(f"Training {month}...")
            train_library: str = libraries_info[LibraryType.TRAIN]
            validation_library: str = libraries_info[LibraryType.VALIDATION]
            try:
                train_df: DataFrame = pd.read_csv(train_library)
                test_df: DataFrame = pd.read_csv(validation_library)
                logger.info(f"Training count: {len(train_df)}")
                logger.info(f"Validation count: {len(test_df)}")

                train_df = train_df.dropna()
                test_df = test_df.dropna()
                logger.info(f"Training count after removing NULLs: {len(train_df)}")
                logger.info(f"Validation count after removing NULLs: {len(test_df)}")
            except (FileNotFoundError, UnicodeDecodeError) as error:
                logger.error(f"{error.__class__.__name__} on {train_library} library.")
                logger.info(Constants.LINE)
                continue

            X_train: np.ndarray = train_df[[col for col in DataColumns]].values
            y_train: np.ndarray = train_df[LabelColumn.COD].values
            X_test: np.ndarray = test_df[[col for col in DataColumns]].values
            y_test: np.ndarray = test_df[LabelColumn.COD].values

            smt = SMOTETomek(random_state=42)
            X_train, y_train = smt.fit_resample(X_train, y_train)

            #
            # scaler = StandardScaler()
            # X_train = scaler.fit_transform(X_train)
            # X_test = scaler.transform(X_test)
            #

            filename: str = self.shared.file_from_path(path=train_library)
            filename_without_ext: str = self.shared.remove_ext(file=filename)
            model_filename = self.shared.add_file_ext(file_name=filename_without_ext, ext=FileType.PKL)
            model_path: str = os.path.join(self.shared.root_folders[RootFolders.MODEL_FOLDER], model_filename)

            clf = RandomForestClassifier(
                random_state=42,
                n_estimators=self.ESTIMATORS,
                n_jobs=self.N_JOBS,
                max_depth=self.MAX_DEPTH,
                min_samples_leaf=4,
                min_samples_split=2,
            )
            clf.fit(X_train, y_train)
            y_pred_test: np.array = clf.predict(X_test)

            accuracy: float | int = accuracy_score(y_test, y_pred_test)
            precision: float | int = precision_score(
                y_test, y_pred_test, average=AccuracyMetrics.ACCURACY_WEIGHTED, zero_division=0
            )
            recall: float | int = recall_score(
                y_test, y_pred_test, average=AccuracyMetrics.ACCURACY_WEIGHTED, zero_division=0
            )
            f1: float | int = f1_score(y_test, y_pred_test, average=AccuracyMetrics.ACCURACY_WEIGHTED, zero_division=0)
            kappa: float | int = cohen_kappa_score(y_test, y_pred_test)

            general_info: str = f"{month.value.upper()} with MAX_DEPTH: {self.MAX_DEPTH} ESTIMATORS: {self.ESTIMATORS}"
            logger.info(general_info)

            accuracy_result: str = f"Accuracy on the test set: {accuracy * 100:.2f}%"
            logger.info(accuracy_result)
            precision_result: str = f"Precision on the test set: {precision * 100:.2f}%"
            logger.info(precision_result)
            recall_result: str = f"Recall on the test set: {recall * 100:.2f}%"
            logger.info(recall_result)
            f1_result: str = f"F1-score on the test set: {f1 * 100:.2f}%"
            logger.info(f1_result)
            kappa_result: str = f"Cohen's Kappa on the test set: {kappa * 100:.2f}%"
            logger.info(kappa_result)

            path_info: str = f"Model saved to: {model_path}"
            messages: List[str] = [
                general_info,
                accuracy_result,
                precision_result,
                recall_result,
                f1_result,
                kappa_result,
                path_info,
                Constants.LINE,
            ]
            self._write_accuracies_to_file(messages=messages)

            with open(model_path, FileMode.WRITE_B) as model_file:
                pickle.dump(clf, model_file)

            logger.info(path_info)
            logger.info(Constants.LINE)

    def _write_accuracies_to_file(self, messages: List[str]) -> None:
        file_path: str = os.path.join(
            self.shared.root_folders[RootFolders.PROGRAM_FOLDER],
            Constants.ACCURACIES_FILE,
        )
        with open(file_path, FileMode.APPEND) as file:
            for message in messages:
                file.write(message + Constants.NEW_LINE)

    def _initialize_file(self) -> None:
        file_path: str = os.path.join(
            self.shared.root_folders[RootFolders.PROGRAM_FOLDER],
            Constants.ACCURACIES_FILE,
        )
        with open(file_path, FileMode.WRITE):
            pass

    def _load_model(self, month: Month | ClassificationType):
        try:
            with open(self.models[month], FileMode.READ_B) as file:
                return pickle.load(file)
        except (FileNotFoundError, pickle.UnpicklingError) as error:
            logger.error(f"{error.__class__.__name__} on {str(month)} model.")
            return None

    @staticmethod
    def _month_map() -> Dict[int, Month]:
        return {i: month_enum for i, month_enum in enumerate(Month, start=1)}

    @staticmethod
    def _get_month(file_name: str) -> int:
        for regex in Regex:
            match = re.search(regex, file_name)
            if match:
                return int(match.group(2))
        raise MonthExtractionException(f"Cannot extract month from {file_name}")

    def _choose_classification_type(self):
        class_type_mapper = {1: ClassificationType.GROUND, 2: ClassificationType.URBAN, 3: ClassificationType.FOREST}
        while True:
            try:
                self._print_classification_types()
                classification_type = int(input("Choose classification type: "))
                return class_type_mapper[classification_type]
            except (KeyError, ValueError):
                self.shared.clear_console()
                logger.error("Invalid classification type")

    @staticmethod
    def _print_classification_types():
        for index, class_type in enumerate(ClassificationType):
            print(f"{index+1}. {class_type}")
